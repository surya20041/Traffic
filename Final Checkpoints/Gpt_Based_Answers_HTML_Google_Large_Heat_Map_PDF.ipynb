{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ce272bd753214c4581a663d1352de470": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fec4f3a6eec24ee28c5f14b4b1a4af51",
              "IPY_MODEL_db18797e4b6648c888328a7a090d5ead",
              "IPY_MODEL_ffb5dc2afc5d4ea797503b55c1f60d72"
            ],
            "layout": "IPY_MODEL_ae9f0e3238f4441dac8fb7409fe7e9ca"
          }
        },
        "fec4f3a6eec24ee28c5f14b4b1a4af51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_098716c4cb9c417fbb4300f953b0611d",
            "placeholder": "​",
            "style": "IPY_MODEL_ee4e7b3f53a947c8a83e0c1f5120b88a",
            "value": "config.json: 100%"
          }
        },
        "db18797e4b6648c888328a7a090d5ead": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c72237289e749eba4a7efe8094ee87e",
            "max": 662,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b3bdbf78c05b429baa9865049d3fa24d",
            "value": 662
          }
        },
        "ffb5dc2afc5d4ea797503b55c1f60d72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82789f95bfe3423cbb3a25a1ef205669",
            "placeholder": "​",
            "style": "IPY_MODEL_a822574493f84e0aabc213ec46afd117",
            "value": " 662/662 [00:00&lt;00:00, 80.7kB/s]"
          }
        },
        "ae9f0e3238f4441dac8fb7409fe7e9ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "098716c4cb9c417fbb4300f953b0611d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee4e7b3f53a947c8a83e0c1f5120b88a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c72237289e749eba4a7efe8094ee87e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3bdbf78c05b429baa9865049d3fa24d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "82789f95bfe3423cbb3a25a1ef205669": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a822574493f84e0aabc213ec46afd117": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86dd7f0cba3b48699084fdf2a96247c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e05cc23f121641fdad20db5e6de206b2",
              "IPY_MODEL_41714b086cdb4f8bb952d88cb7e2dd40",
              "IPY_MODEL_b1d524c540874729af68aa497e7357d4"
            ],
            "layout": "IPY_MODEL_cf2c8651dd694a59a1807eac671c3206"
          }
        },
        "e05cc23f121641fdad20db5e6de206b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c63101885884b3791c41bb36e7802fe",
            "placeholder": "​",
            "style": "IPY_MODEL_996bda6fdef94f57b80913e213f1b73a",
            "value": "model.safetensors: 100%"
          }
        },
        "41714b086cdb4f8bb952d88cb7e2dd40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ccdfe10c1ca40cc91227821740aee15",
            "max": 3132668804,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_50d3bf0bf12c4237bf55e327c330dadd",
            "value": 3132668804
          }
        },
        "b1d524c540874729af68aa497e7357d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecd796a699654bdfb1de9a3370410f2f",
            "placeholder": "​",
            "style": "IPY_MODEL_b1d6d2b3220b48d1ae08f1de92cb4694",
            "value": " 3.13G/3.13G [00:25&lt;00:00, 127MB/s]"
          }
        },
        "cf2c8651dd694a59a1807eac671c3206": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c63101885884b3791c41bb36e7802fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "996bda6fdef94f57b80913e213f1b73a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ccdfe10c1ca40cc91227821740aee15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50d3bf0bf12c4237bf55e327c330dadd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ecd796a699654bdfb1de9a3370410f2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1d6d2b3220b48d1ae08f1de92cb4694": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21499c6654e84747836989f8a5cb3341": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75c39fe1fc95439db2c05780d17a670d",
              "IPY_MODEL_b8303f3f282346c59ac54fedc1f0a869",
              "IPY_MODEL_cf0af215c75042ffac849cffc787f94f"
            ],
            "layout": "IPY_MODEL_e6f057248c714a9b8b3f666bc86d38ec"
          }
        },
        "75c39fe1fc95439db2c05780d17a670d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c57704e3fe64a339407c15eddc5d679",
            "placeholder": "​",
            "style": "IPY_MODEL_0457d42601f1487db124a6749420afdc",
            "value": "generation_config.json: 100%"
          }
        },
        "b8303f3f282346c59ac54fedc1f0a869": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_834bf2ced6ab42e39b2d6a762d60da14",
            "max": 147,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cd1f0d79716e4838920062323f13a55a",
            "value": 147
          }
        },
        "cf0af215c75042ffac849cffc787f94f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_699878b8d2df4b03b7b2395c61b58027",
            "placeholder": "​",
            "style": "IPY_MODEL_b732d26a7e554eb9b18c319b34b8607b",
            "value": " 147/147 [00:00&lt;00:00, 22.1kB/s]"
          }
        },
        "e6f057248c714a9b8b3f666bc86d38ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c57704e3fe64a339407c15eddc5d679": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0457d42601f1487db124a6749420afdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "834bf2ced6ab42e39b2d6a762d60da14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd1f0d79716e4838920062323f13a55a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "699878b8d2df4b03b7b2395c61b58027": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b732d26a7e554eb9b18c319b34b8607b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e94162eac57544aa9f8c10c79771b05f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_96a9d9eb6e754379b87811834e760d5d",
              "IPY_MODEL_2384453afe254b518e30ec3c2fc94952",
              "IPY_MODEL_569ab38150214f4aad9ef019d4f98b52"
            ],
            "layout": "IPY_MODEL_1ea083a00bb34126848df779768c8972"
          }
        },
        "96a9d9eb6e754379b87811834e760d5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8de0d17a9e2e416f86b2552860fadf81",
            "placeholder": "​",
            "style": "IPY_MODEL_20230f87c44f43dea784a6a51d3ed7c4",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "2384453afe254b518e30ec3c2fc94952": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_655d1fcfdda1461a80252468a57bfc50",
            "max": 2539,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e274f5418954492a98154057e059592",
            "value": 2539
          }
        },
        "569ab38150214f4aad9ef019d4f98b52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2039bc802db749a49e50d3d6b084a2bf",
            "placeholder": "​",
            "style": "IPY_MODEL_f65d6fb15bc34937b64ca3ef20388571",
            "value": " 2.54k/2.54k [00:00&lt;00:00, 399kB/s]"
          }
        },
        "1ea083a00bb34126848df779768c8972": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8de0d17a9e2e416f86b2552860fadf81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20230f87c44f43dea784a6a51d3ed7c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "655d1fcfdda1461a80252468a57bfc50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e274f5418954492a98154057e059592": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2039bc802db749a49e50d3d6b084a2bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f65d6fb15bc34937b64ca3ef20388571": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8286ff3f92a942068ffc6be599ae5064": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_23e71c6333624c44b31a9141585ef837",
              "IPY_MODEL_6ef7e66074ff4b959d8168c4595d36ca",
              "IPY_MODEL_ee7ad369e2a549b8aceb2520a33222b6"
            ],
            "layout": "IPY_MODEL_82cff09161984fb8b30189706a1f2b98"
          }
        },
        "23e71c6333624c44b31a9141585ef837": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a00e4c2a89aa4419a11e1178c19eb45b",
            "placeholder": "​",
            "style": "IPY_MODEL_8b38eed874dc497f8c337d1d2cb7b799",
            "value": "spiece.model: 100%"
          }
        },
        "6ef7e66074ff4b959d8168c4595d36ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f64c23c26a8f4e48b07c79b79667b7fc",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a6107a2ee9b84ed78ba733f506d6f39b",
            "value": 791656
          }
        },
        "ee7ad369e2a549b8aceb2520a33222b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74b6aedf17fd4759a6b4487a5bf0b40f",
            "placeholder": "​",
            "style": "IPY_MODEL_4fa6657de7894c898eb322f0f19b950b",
            "value": " 792k/792k [00:00&lt;00:00, 49.0MB/s]"
          }
        },
        "82cff09161984fb8b30189706a1f2b98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a00e4c2a89aa4419a11e1178c19eb45b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b38eed874dc497f8c337d1d2cb7b799": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f64c23c26a8f4e48b07c79b79667b7fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6107a2ee9b84ed78ba733f506d6f39b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "74b6aedf17fd4759a6b4487a5bf0b40f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fa6657de7894c898eb322f0f19b950b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b315f15b7a894d83bb8e31f52931276b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_395239a18aad4603baf4faac7b521161",
              "IPY_MODEL_3b27c3ed61a44a31982dcd720ff42453",
              "IPY_MODEL_367649468c3c40bcb88eb821a229ee93"
            ],
            "layout": "IPY_MODEL_80ae2fe68489447bbb365affc976a15e"
          }
        },
        "395239a18aad4603baf4faac7b521161": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc96ba90e41d4dd18863eeefd840502b",
            "placeholder": "​",
            "style": "IPY_MODEL_66ab0df0c6db4ea18eeaaefbf6229987",
            "value": "tokenizer.json: 100%"
          }
        },
        "3b27c3ed61a44a31982dcd720ff42453": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_544c49ae0d8c4835a8cae7a75e8ed6e3",
            "max": 2424064,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3bcc2edcbd0944e1a0b0853bad38524d",
            "value": 2424064
          }
        },
        "367649468c3c40bcb88eb821a229ee93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41ce865046724eb286594c902afe5861",
            "placeholder": "​",
            "style": "IPY_MODEL_9cc9846554d046a78b80dfd8edffa91d",
            "value": " 2.42M/2.42M [00:00&lt;00:00, 31.2MB/s]"
          }
        },
        "80ae2fe68489447bbb365affc976a15e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc96ba90e41d4dd18863eeefd840502b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66ab0df0c6db4ea18eeaaefbf6229987": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "544c49ae0d8c4835a8cae7a75e8ed6e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bcc2edcbd0944e1a0b0853bad38524d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "41ce865046724eb286594c902afe5861": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cc9846554d046a78b80dfd8edffa91d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07ed84259ec64b2bb95b76a8010bc6bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e2099dae21b44c09a78b947f618666ef",
              "IPY_MODEL_5789d402bea1468f94fbd1069fe6d4cc",
              "IPY_MODEL_e3a41a8786e24aad8890e96e1a8bfe6f"
            ],
            "layout": "IPY_MODEL_07c81bd2c5534e4a9b8487170993c95d"
          }
        },
        "e2099dae21b44c09a78b947f618666ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4734d02ab98f4e33a86d4962e3bf167a",
            "placeholder": "​",
            "style": "IPY_MODEL_f211367c35ad4a998bbc2199a9bc7c11",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "5789d402bea1468f94fbd1069fe6d4cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bddde1a956f7446692d70dae4344d79e",
            "max": 2201,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fb41bc8dc71d4a4890249d7933d34098",
            "value": 2201
          }
        },
        "e3a41a8786e24aad8890e96e1a8bfe6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fcd8d3a102f844d49ccbe4a8071adf51",
            "placeholder": "​",
            "style": "IPY_MODEL_11ddbc6a2fe945718a84ef589eff3a40",
            "value": " 2.20k/2.20k [00:00&lt;00:00, 334kB/s]"
          }
        },
        "07c81bd2c5534e4a9b8487170993c95d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4734d02ab98f4e33a86d4962e3bf167a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f211367c35ad4a998bbc2199a9bc7c11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bddde1a956f7446692d70dae4344d79e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb41bc8dc71d4a4890249d7933d34098": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fcd8d3a102f844d49ccbe4a8071adf51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11ddbc6a2fe945718a84ef589eff3a40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hdBDg-UV9S2",
        "outputId": "9646ba4a-c876-43b5-93bb-216cbc4e10fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) y\n",
            "Token is valid (permission: fineGrained).\n",
            "The token `Inference_API_KEY_8B` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `Inference_API_KEY_8B`\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rouqQSM0acVe",
        "outputId": "189904ee-1ee8-41da-d5b9-4990d7276827"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.111-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Collecting opencv-python>=4.6.0 (from ultralytics)\n",
            "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.14.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cpu)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cpu)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Collecting py-cpuinfo (from ultralytics)\n",
            "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.111-py3-none-any.whl (978 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m978.8/978.8 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: py-cpuinfo, opencv-python, ultralytics-thop, ultralytics\n",
            "Successfully installed opencv-python-4.11.0.86 py-cpuinfo-9.0.0 ultralytics-8.3.111 ultralytics-thop-2.0.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Kvy8FHnoOj2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python numpy ultralytics transformers pillow matplotlib seaborn pandas torch reportlab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDQ9BsGKsEH7",
        "outputId": "bfb4a623-d090-4eef-9386-dd1c38729b5b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.111)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cpu)\n",
            "Collecting reportlab\n",
            "  Downloading reportlab-4.4.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.14.1)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cpu)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Collecting chardet (from reportlab)\n",
            "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading reportlab-4.4.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: chardet, reportlab\n",
            "Successfully installed chardet-5.2.0 reportlab-4.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "from transformers import pipeline, T5ForConditionalGeneration, T5Tokenizer\n",
        "from PIL import Image\n",
        "import re\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import os\n",
        "import torch\n",
        "import gc\n",
        "from reportlab.lib.pagesizes import letter\n",
        "from reportlab.lib import colors\n",
        "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, Image as ReportLabImage\n",
        "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
        "from reportlab.lib.units import inch\n",
        "\n",
        "# Install dependencies\n",
        "print(\"Installing dependencies...\")\n",
        "!pip install opencv-python numpy ultralytics transformers pillow matplotlib seaborn pandas torch reportlab\n",
        "\n",
        "# Clear any lingering GPU memory (though we're running on CPU)\n",
        "torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
        "gc.collect()\n",
        "\n",
        "# Verify input files\n",
        "model_path = r\"/content/best.pt\"\n",
        "video_path = r\"/content/test_10s.mp4\"\n",
        "if not os.path.exists(model_path):\n",
        "    print(f\"Error: YOLO model file not found at {model_path}\")\n",
        "    exit()\n",
        "if not os.path.exists(video_path):\n",
        "    print(f\"Error: Video file not found at {video_path}\")\n",
        "    exit()\n",
        "\n",
        "# Load YOLO model\n",
        "try:\n",
        "    model = YOLO(model_path)\n",
        "    print(\"YOLO model loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading YOLO model: {e}\")\n",
        "    exit()\n",
        "\n",
        "# Video setup\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "if not cap.isOpened():\n",
        "    print(f\"Error: Could not open video at {video_path}\")\n",
        "    exit()\n",
        "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "middle_index = total_frames // 2 if total_frames > 0 else -1\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "selected_frame = None\n",
        "peak_frame = None\n",
        "vehicle_counts = {}\n",
        "track_id_to_class = {}\n",
        "frame_vehicle_counts = []\n",
        "frame_index = 0\n",
        "max_vehicles = 0\n",
        "max_frame_index = 0\n",
        "emergency_alerts = []\n",
        "track_positions = defaultdict(list)\n",
        "average_speeds = {}\n",
        "congestion_indices = []\n",
        "\n",
        "# Process video\n",
        "print(\"Processing video...\")\n",
        "while cap.isOpened():\n",
        "    success, frame = cap.read()\n",
        "    if not success:\n",
        "        break\n",
        "    frame = cv2.resize(frame, (700, 500))\n",
        "    results = model.track(frame, persist=True)\n",
        "    boxes = results[0].boxes.xyxy.cpu().numpy()\n",
        "    confidences = results[0].boxes.conf.cpu().numpy()\n",
        "    classes = results[0].boxes.cls.cpu().numpy().astype(int)\n",
        "    track_ids = results[0].boxes.id.cpu().numpy() if results[0].boxes.id is not None else []\n",
        "\n",
        "    # Unique vehicle counts and speed estimation\n",
        "    current_frame_counts = defaultdict(int)\n",
        "    for conf, cls, track_id, box in zip(confidences, classes, track_ids, boxes):\n",
        "        if conf < 0.5:\n",
        "            continue\n",
        "        label = results[0].names[cls]\n",
        "        if track_id not in track_id_to_class:\n",
        "            track_id_to_class[track_id] = label\n",
        "            vehicle_counts[label] = vehicle_counts.get(label, 0) + 1\n",
        "        current_frame_counts[label] += 1\n",
        "        # Track position for speed\n",
        "        center_x = (box[0] + box[2]) / 2\n",
        "        center_y = (box[1] + box[3]) / 2\n",
        "        track_positions[track_id].append((frame_index, center_x, center_y))\n",
        "\n",
        "    frame_vehicle_counts.append(dict(current_frame_counts))\n",
        "\n",
        "    # Emergency vehicle alerts\n",
        "    if current_frame_counts.get(\"Ambulance\", 0) > 1:\n",
        "        alert = f\"High ambulance activity at {frame_index/fps:.2f}s: {current_frame_counts['Ambulance']} ambulances\"\n",
        "        emergency_alerts.append(alert)\n",
        "        print(f\"Emergency alert: {alert}\")\n",
        "\n",
        "    # Congestion index\n",
        "    total_in_frame = sum(current_frame_counts.values())\n",
        "    congestion_index = total_in_frame / 5.0\n",
        "    congestion_indices.append(congestion_index)\n",
        "    if total_in_frame > max_vehicles:\n",
        "        max_vehicles = total_in_frame\n",
        "        max_frame_index = frame_index\n",
        "        peak_frame = results[0].plot()\n",
        "\n",
        "    # Save middle frame\n",
        "    if frame_index == middle_index:\n",
        "        selected_frame = results[0].plot()\n",
        "\n",
        "    frame_index += 1\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "print(f\"Video processing complete: {total_frames} frames processed.\")\n",
        "\n",
        "# Calculate average speeds\n",
        "print(\"Calculating average speeds...\")\n",
        "for track_id, positions in track_positions.items():\n",
        "    label = track_id_to_class[track_id]\n",
        "    if len(positions) < 2:\n",
        "        continue\n",
        "    total_speed = 0\n",
        "    count = 0\n",
        "    for i in range(1, len(positions)):\n",
        "        frame_diff = positions[i][0] - positions[i-1][0]\n",
        "        if frame_diff == 0:\n",
        "            continue\n",
        "        dx = positions[i][1] - positions[i-1][1]\n",
        "        dy = positions[i][2] - positions[i-1][2]\n",
        "        distance = np.sqrt(dx**2 + dy**2)\n",
        "        time = frame_diff / fps\n",
        "        speed = distance / time\n",
        "        total_speed += speed\n",
        "        count += 1\n",
        "    if count > 0:\n",
        "        avg_speed = total_speed / count\n",
        "        average_speeds[label] = average_speeds.get(label, 0) + avg_speed\n",
        "        average_speeds[f\"{label}_count\"] = average_speeds.get(f\"{label}_count\", 0) + 1\n",
        "\n",
        "for label in vehicle_counts.keys():\n",
        "    count_key = f\"{label}_count\"\n",
        "    if count_key in average_speeds:\n",
        "        average_speeds[label] = average_speeds[label] / average_speeds[count_key]\n",
        "        del average_speeds[count_key]\n",
        "\n",
        "# Save annotated frames\n",
        "try:\n",
        "    if selected_frame is not None:\n",
        "        cv2.imwrite(\"middle_frame.jpg\", selected_frame)\n",
        "        print(\"Middle frame saved as 'middle_frame.jpg'.\")\n",
        "    else:\n",
        "        print(\"Warning: Middle frame not saved.\")\n",
        "    if peak_frame is not None:\n",
        "        cv2.imwrite(\"peak_frame.jpg\", peak_frame)\n",
        "        print(\"Peak frame saved as 'peak_frame.jpg'.\")\n",
        "    else:\n",
        "        print(\"Warning: Peak frame not saved.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving frames: {e}\")\n",
        "\n",
        "# Convert middle frame to PIL\n",
        "if selected_frame is not None:\n",
        "    selected_frame_rgb = cv2.cvtColor(selected_frame, cv2.COLOR_BGR2RGB)\n",
        "    selected_frame_pil = Image.fromarray(selected_frame_rgb)\n",
        "else:\n",
        "    print(\"Warning: No middle frame selected for PIL conversion.\")\n",
        "    selected_frame_pil = None\n",
        "\n",
        "# Load report pipeline\n",
        "print(\"Loading report pipeline...\")\n",
        "try:\n",
        "    pipe = pipeline(\"text2text-generation\", model=\"google/flan-t5-small\")\n",
        "    print(\"Flan-T5-Small loaded for report generation.\")\n",
        "except Exception as e:\n",
        "    print(f\"Report model error: {e}\")\n",
        "    pipe = None\n",
        "\n",
        "# Load chatbot model\n",
        "print(\"Loading Flan-T5-Large chatbot model...\")\n",
        "try:\n",
        "    chatbot = pipeline(\"text2text-generation\", model=\"google/flan-t5-large\")\n",
        "    print(\"Flan-T5-Large loaded for chatbot.\")\n",
        "except Exception as e:\n",
        "    print(f\"Flan-T5-Large error: {e}\")\n",
        "    print(\"Chatbot unavailable. Using rule-based answers only.\")\n",
        "    chatbot = None\n",
        "finally:\n",
        "    gc.collect()\n",
        "\n",
        "# Calculate averages and congestion\n",
        "average_counts = {}\n",
        "for vtype in vehicle_counts.keys():\n",
        "    total = sum(frame_counts.get(vtype, 0) for frame_counts in frame_vehicle_counts)\n",
        "    average_counts[vtype] = total / len(frame_vehicle_counts) if frame_vehicle_counts else 0\n",
        "max_time_sec = max_frame_index / fps if fps > 0 else 0\n",
        "average_congestion = np.mean(congestion_indices) if congestion_indices else 0\n",
        "\n",
        "# Generate traffic density heatmap\n",
        "print(\"Generating traffic density heatmap...\")\n",
        "times = [i / fps for i in range(len(frame_vehicle_counts))]\n",
        "total_vehicles_per_frame = [sum(frame_counts.values()) for frame_counts in frame_vehicle_counts]\n",
        "plt.figure(figsize=(10, 4))\n",
        "sns.heatmap([total_vehicles_per_frame], cmap=\"YlOrRd\", xticklabels=50, cbar_kws={'label': 'Vehicle Count'})\n",
        "plt.xlabel(\"Time (seconds)\")\n",
        "plt.ylabel(\"Density\")\n",
        "plt.title(\"Traffic Density Heatmap\")\n",
        "plt.xticks(ticks=np.linspace(0, len(times)-1, 5), labels=[f\"{t:.1f}\" for t in np.linspace(0, max(times), 5)])\n",
        "try:\n",
        "    plt.savefig(\"heatmap.png\")\n",
        "    plt.close()\n",
        "    print(\"Heatmap saved as 'heatmap.png'.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving heatmap: {e}\")\n",
        "\n",
        "# Export to CSV\n",
        "print(\"Exporting data to CSV...\")\n",
        "csv_data = {\n",
        "    \"Frame\": list(range(len(frame_vehicle_counts))),\n",
        "    \"Time (s)\": times,\n",
        "    \"Total Vehicles\": total_vehicles_per_frame,\n",
        "    \"Congestion Index\": congestion_indices\n",
        "}\n",
        "for vtype in vehicle_counts.keys():\n",
        "    csv_data[vtype] = [frame_counts.get(vtype, 0) for frame_counts in frame_vehicle_counts]\n",
        "df = pd.DataFrame(csv_data)\n",
        "try:\n",
        "    df.to_csv(\"traffic_data.csv\", index=False)\n",
        "    print(\"Traffic data exported to 'traffic_data.csv'.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error exporting CSV: {e}\")\n",
        "\n",
        "# Generate text report\n",
        "print(\"Generating text report...\")\n",
        "report_prompt = (\n",
        "    f\"Vehicle Detection Report:\\n\"\n",
        "    f\"Unique vehicle counts across all frames:\\n\"\n",
        ")\n",
        "for vtype, count in vehicle_counts.items():\n",
        "    report_prompt += f\"{vtype}: {count}\\n\"\n",
        "report_prompt += \"Additional Insights:\\n\"\n",
        "report_prompt += \"Average vehicles per frame:\\n\"\n",
        "for vtype, avg in average_counts.items():\n",
        "    report_prompt += f\"{vtype}: {avg:.2f}\\n\"\n",
        "report_prompt += f\"Average speeds (pixels/s):\\n\"\n",
        "for vtype, speed in average_speeds.items():\n",
        "    report_prompt += f\"{vtype}: {speed:.2f}\\n\"\n",
        "report_prompt += f\"Peak traffic at {max_time_sec:.2f} seconds with {max_vehicles} vehicles.\\n\"\n",
        "report_prompt += f\"Average congestion index: {average_congestion:.2f} (0=low, 1=moderate, >2=high).\\n\"\n",
        "if emergency_alerts:\n",
        "    report_prompt += \"Emergency Alerts:\\n\" + \"\\n\".join(emergency_alerts) + \"\\n\"\n",
        "if frame_vehicle_counts and middle_index < len(frame_vehicle_counts):\n",
        "    selected_counts = frame_vehicle_counts[middle_index]\n",
        "    report_prompt += \"Selected middle frame shows:\\n\"\n",
        "    for vtype, count in selected_counts.items():\n",
        "        report_prompt += f\"{vtype}: {count}\\n\"\n",
        "report_prompt += \"Generate a detailed summary based on this data and describe the scene in the selected frame.\"\n",
        "\n",
        "try:\n",
        "    if pipe:\n",
        "        result = pipe(report_prompt, max_new_tokens=300)\n",
        "        report_text = result[0]['generated_text']\n",
        "        print(\"Text report generated with text model.\")\n",
        "    else:\n",
        "        report_text = \"Report failed. Counts:\\n\" + \"\\n\".join([f\"{v}: {c}\" for v, c in vehicle_counts.items()])\n",
        "        print(\"Warning: Text report generation failed, using fallback.\")\n",
        "except Exception as e:\n",
        "    print(f\"Report error: {e}\")\n",
        "    report_text = \"Report failed. Counts:\\n\" + \"\\n\".join([f\"{v}: {c}\" for v, c in vehicle_counts.items()])\n",
        "    print(\"Warning: Text report generation failed, using fallback.\")\n",
        "\n",
        "print(\"\\n--- Generated Report ---\\n\")\n",
        "print(report_text)\n",
        "\n",
        "# Visualization Dashboard\n",
        "print(\"Generating visualization dashboard...\")\n",
        "fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(10, 20))\n",
        "ax1.plot(times, total_vehicles_per_frame, color='blue')\n",
        "ax1.set_xlabel('Time (seconds)')\n",
        "ax1.set_ylabel('Total Vehicles')\n",
        "ax1.set_title('Total Vehicles Over Time')\n",
        "ax1.grid(True)\n",
        "vehicle_types = list(vehicle_counts.keys())\n",
        "for vtype in vehicle_types:\n",
        "    counts = [frame_counts.get(vtype, 0) for frame_counts in frame_vehicle_counts]\n",
        "    ax2.plot(times, counts, label=vtype)\n",
        "ax2.set_xlabel('Time (seconds)')\n",
        "ax2.set_ylabel('Vehicle Count')\n",
        "ax2.set_title('Vehicle Counts by Type Over Time')\n",
        "ax2.legend()\n",
        "ax2.grid(True)\n",
        "ax3.bar(vehicle_types, [vehicle_counts[vtype] for vtype in vehicle_types], color='green')\n",
        "ax3.set_xlabel('Vehicle Type')\n",
        "ax3.set_ylabel('Unique Count')\n",
        "ax3.set_title('Unique Vehicle Counts')\n",
        "ax3.grid(True, axis='y')\n",
        "ax4.bar(vehicle_types, [average_speeds.get(vtype, 0) for vtype in vehicle_types], color='orange')\n",
        "ax4.set_xlabel('Vehicle Type')\n",
        "ax4.set_ylabel('Average Speed (pixels/s)')\n",
        "ax4.set_title('Average Vehicle Speeds')\n",
        "ax4.grid(True, axis='y')\n",
        "plt.tight_layout()\n",
        "try:\n",
        "    plt.savefig(\"dashboard.png\")\n",
        "    plt.close()\n",
        "    print(\"Dashboard saved as 'dashboard.png'.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving dashboard: {e}\")\n",
        "\n",
        "# Generate PDF report\n",
        "print(\"Generating PDF report...\")\n",
        "try:\n",
        "    pdf = SimpleDocTemplate(\"report.pdf\", pagesize=letter)\n",
        "    styles = getSampleStyleSheet()\n",
        "    normal_style = ParagraphStyle(name='NormalWrap', parent=styles['Normal'], wordWrap='CJK')\n",
        "    heading_style = styles['Heading1']\n",
        "    subheading_style = styles['Heading2']\n",
        "    elements = []\n",
        "\n",
        "    # Title\n",
        "    elements.append(Paragraph(\"Vehicle Detection Report\", heading_style))\n",
        "    elements.append(Spacer(1, 0.2 * inch))\n",
        "\n",
        "    # Summary\n",
        "    elements.append(Paragraph(\"Summary\", subheading_style))\n",
        "    elements.append(Spacer(1, 0.1 * inch))\n",
        "    report_text_lines = report_text.split('\\n')\n",
        "    for line in report_text_lines:\n",
        "        elements.append(Paragraph(line, normal_style))\n",
        "    elements.append(Spacer(1, 0.2 * inch))\n",
        "\n",
        "    # Vehicle Statistics Table\n",
        "    elements.append(Paragraph(\"Vehicle Statistics\", subheading_style))\n",
        "    elements.append(Spacer(1, 0.1 * inch))\n",
        "    table_data = [['Vehicle Type', 'Unique Count', 'Avg/Frame', 'Middle Frame', 'Avg Speed (px/s)']]\n",
        "    for vtype in vehicle_counts.keys():\n",
        "        unique_count = vehicle_counts.get(vtype, 0)\n",
        "        avg_count = average_counts.get(vtype, 0)\n",
        "        middle_count = frame_vehicle_counts[middle_index].get(vtype, 0) if middle_index < len(frame_vehicle_counts) else 0\n",
        "        speed = average_speeds.get(vtype, 0)\n",
        "        table_data.append([vtype, str(unique_count), f\"{avg_count:.2f}\", str(middle_count), f\"{speed:.2f}\"])\n",
        "    table = Table(table_data)\n",
        "    table.setStyle(TableStyle([\n",
        "        ('BACKGROUND', (0, 0), (-1, 0), colors.grey),\n",
        "        ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),\n",
        "        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
        "        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
        "        ('FONTSIZE', (0, 0), (-1, 0), 10),\n",
        "        ('BOTTOMPADDING', (0, 0), (-1, 0), 12),\n",
        "        ('BACKGROUND', (0, 1), (-1, -1), colors.beige),\n",
        "        ('GRID', (0, 0), (-1, -1), 1, colors.black)\n",
        "    ]))\n",
        "    elements.append(table)\n",
        "    elements.append(Spacer(1, 0.2 * inch))\n",
        "\n",
        "    # Key Insights\n",
        "    elements.append(Paragraph(\"Key Insights\", subheading_style))\n",
        "    elements.append(Spacer(1, 0.1 * inch))\n",
        "    elements.append(Paragraph(f\"Peak traffic occurred at {max_time_sec:.2f} seconds with {max_vehicles} vehicles.\", normal_style))\n",
        "    elements.append(Paragraph(f\"Average congestion index: {average_congestion:.2f} (0=low, 1=moderate, >2=high).\", normal_style))\n",
        "    if emergency_alerts:\n",
        "        elements.append(Paragraph(\"Emergency Alerts:\", normal_style))\n",
        "        for alert in emergency_alerts:\n",
        "            elements.append(Paragraph(f\"- {alert}\", normal_style))\n",
        "    elements.append(Spacer(1, 0.2 * inch))\n",
        "\n",
        "    # Visualizations\n",
        "    elements.append(Paragraph(\"Visualizations\", subheading_style))\n",
        "    elements.append(Spacer(1, 0.1 * inch))\n",
        "    image_paths = [\n",
        "        (\"dashboard.png\", \"Visualization Dashboard\"),\n",
        "        (\"heatmap.png\", \"Traffic Density Heatmap\"),\n",
        "        (\"middle_frame.jpg\", \"Middle Frame\"),\n",
        "        (\"peak_frame.jpg\", \"Peak Traffic Frame\")\n",
        "    ]\n",
        "    for path, title in image_paths:\n",
        "        if os.path.exists(path):\n",
        "            try:\n",
        "                img = ReportLabImage(path, width=5*inch, height=3*inch)\n",
        "                elements.append(Paragraph(title, normal_style))\n",
        "                elements.append(img)\n",
        "                elements.append(Spacer(1, 0.1 * inch))\n",
        "            except Exception as e:\n",
        "                print(f\"Error adding image {path} to PDF: {e}\")\n",
        "                elements.append(Paragraph(f\"{title} not available.\", normal_style))\n",
        "                elements.append(Spacer(1, 0.1 * inch))\n",
        "        else:\n",
        "            print(f\"Warning: Image {path} not found.\")\n",
        "            elements.append(Paragraph(f\"{title} not available.\", normal_style))\n",
        "            elements.append(Spacer(1, 0.1 * inch))\n",
        "\n",
        "    # Note\n",
        "    elements.append(Paragraph(\"Note: This PDF contains the complete vehicle detection report.\", normal_style))\n",
        "\n",
        "    # Build PDF\n",
        "    pdf.build(elements)\n",
        "    print(\"PDF report generated as 'report.pdf'.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error generating PDF: {e}\")\n",
        "\n",
        "# Create optimized context for chatbot\n",
        "context = (\n",
        "    f\"Video Analysis: {total_frames} frames, {(total_frames/fps):.2f}s, {fps:.2f} FPS.\\n\"\n",
        "    f\"Unique vehicles: {', '.join([f'{v}: {c}' for v, c in vehicle_counts.items()])} (total: {sum(vehicle_counts.values())}).\\n\"\n",
        "    f\"Average per frame: {', '.join([f'{v}: {c:.2f}' for v, c in average_counts.items()])}.\\n\"\n",
        "    f\"Average speeds (pixels/s): {', '.join([f'{v}: {s:.2f}' for v, s in average_speeds.items()])}.\\n\"\n",
        "    f\"Peak traffic: {max_vehicles} vehicles at {max_time_sec:.2f}s.\\n\"\n",
        "    f\"Middle frame ({middle_index/fps:.2f}s): {', '.join([f'{v}: {c}' for v, c in frame_vehicle_counts[middle_index].items()]) if middle_index < len(frame_vehicle_counts) else 'no vehicles'}.\\n\"\n",
        "    f\"Vehicle types: {', '.join(vehicle_counts.keys())}.\\n\"\n",
        "    f\"Traffic: {'Heavy' if sum(vehicle_counts.values()) > 30 else 'Moderate' if sum(vehicle_counts.values()) > 15 else 'Light'}.\\n\"\n",
        "    f\"Congestion index: {average_congestion:.2f} (0=low, 1=moderate, >2=high).\\n\"\n",
        ")\n",
        "if emergency_alerts:\n",
        "    context += f\"Emergency alerts: {'; '.join(emergency_alerts)}.\\n\"\n",
        "print(\"\\nChatbot context:\\n\", context)\n",
        "\n",
        "# Updated answer_question function\n",
        "def answer_question(question, vehicle_counts, frame_vehicle_counts, fps, total_frames, average_counts, max_time_sec, max_vehicles, context, chatbot, average_speeds, congestion_indices, emergency_alerts):\n",
        "    question = question.lower().strip()\n",
        "    if not question:\n",
        "        return \"Please ask a valid question.\"\n",
        "\n",
        "    # Rule-based answers\n",
        "    time_match = re.search(r\"at (\\d+) seconds\", question)\n",
        "    if time_match:\n",
        "        time_sec = int(time_match.group(1))\n",
        "        if time_sec * fps >= total_frames:\n",
        "            return f\"Time {time_sec} seconds exceeds video duration ({total_frames/fps:.2f}s).\"\n",
        "        frame_index = min(int(time_sec * fps), total_frames - 1)\n",
        "        frame_counts = frame_vehicle_counts[frame_index]\n",
        "        for vtype in vehicle_counts.keys():\n",
        "            if vtype.lower() in question:\n",
        "                count = frame_counts.get(vtype, 0)\n",
        "                return f\"At {time_sec} seconds, there were {count} {vtype}(s).\"\n",
        "        if \"traffic\" in question or \"how many\" in question:\n",
        "            counts_str = \", \".join([f\"{count} {vtype}(s)\" for vtype, count in frame_counts.items()])\n",
        "            return f\"At {time_sec} seconds: {counts_str or 'no vehicles'}.\"\n",
        "        total = sum(frame_counts.values())\n",
        "        return f\"At {time_sec} seconds, there were {total} vehicles.\"\n",
        "\n",
        "    if \"peak\" in question and \"time\" in question:\n",
        "        return f\"Peak traffic was at {max_time_sec:.2f} seconds with {max_vehicles} vehicles.\"\n",
        "\n",
        "    if \"average\" in question and \"speed\" in question:\n",
        "        for vtype in vehicle_counts.keys():\n",
        "            if vtype.lower() in question:\n",
        "                speed = average_speeds.get(vtype, 0)\n",
        "                return f\"Average speed of {vtype}s: {speed:.2f} pixels/s.\"\n",
        "        speeds_str = \", \".join([f\"{vtype}: {speed:.2f} pixels/s\" for vtype, speed in average_speeds.items()])\n",
        "        return f\"Average speeds: {speeds_str or 'none'}.\"\n",
        "\n",
        "    if \"average\" in question:\n",
        "        for vtype in vehicle_counts.keys():\n",
        "            if vtype.lower() in question:\n",
        "                avg = average_counts.get(vtype, 0)\n",
        "                return f\"Average {vtype}s per frame: {avg:.2f}.\"\n",
        "        averages_str = \", \".join([f\"{vtype}: {avg:.2f}\" for vtype, avg in average_counts.items()])\n",
        "        return f\"Average vehicles per frame: {averages_str or 'none'}.\"\n",
        "\n",
        "    if re.search(r\"how many (total |)vehicles\", question) or \"total number\" in question:\n",
        "        total = sum(vehicle_counts.values())\n",
        "        return f\"Total unique vehicles: {total}.\"\n",
        "\n",
        "    for vtype, count in vehicle_counts.items():\n",
        "        type_lower = vtype.lower()\n",
        "        if any(phrase in question for phrase in [f\"how many {type_lower}\", f\"number of {type_lower}\", f\"how many {type_lower}s\", f\"{type_lower}s in the video\", f\"{type_lower} in the video\"]):\n",
        "            return f\"Unique {vtype}(s) detected: {count}.\"\n",
        "\n",
        "    if \"most common\" in question or \"most frequent\" in question:\n",
        "        if vehicle_counts:\n",
        "            most_common = max(vehicle_counts.items(), key=lambda x: x[1])\n",
        "            return f\"Most common vehicle: {most_common[0]} ({most_common[1]} instances).\"\n",
        "        return \"No vehicles detected.\"\n",
        "\n",
        "    if \"what types\" in question or \"vehicle types\" in question or \"which vehicles\" in question:\n",
        "        if vehicle_counts:\n",
        "            types = list(vehicle_counts.keys())\n",
        "            types_str = \", \".join(types[:-1]) + \" and \" + types[-1] if len(types) > 1 else types[0]\n",
        "            return f\"Vehicle types: {types_str}.\"\n",
        "        return \"No vehicles detected.\"\n",
        "\n",
        "    if \"traffic\" in question and (\"condition\" in question or \"overall\" in question):\n",
        "        total = sum(vehicle_counts.values())\n",
        "        condition = \"heavy\" if total > 30 else \"moderate\" if total > 15 else \"light\"\n",
        "        return f\"Traffic was {condition} with {total} unique vehicles.\"\n",
        "\n",
        "    if \"congestion\" in question or \"congested\" in question:\n",
        "        avg_congestion = np.mean(congestion_indices) if congestion_indices else 0\n",
        "        level = \"high\" if avg_congestion > 2 else \"moderate\" if avg_congestion > 1 else \"low\"\n",
        "        return f\"Average congestion index: {avg_congestion:.2f} ({level}).\"\n",
        "\n",
        "    if \"emergency\" in question or \"alerts\" in question or \"ambulance activity\" in question:\n",
        "        if emergency_alerts:\n",
        "            return f\"Emergency alerts: {'; '.join(emergency_alerts)}.\"\n",
        "        return \"No emergency alerts detected.\"\n",
        "\n",
        "    # Rule-based fallback if chatbot is unavailable\n",
        "    if not chatbot:\n",
        "        if any(kw in question for kw in [\"describe\", \"tell me\", \"what can you say\", \"interesting\", \"summarize\", \"activity\", \"happening\"]):\n",
        "            total = sum(vehicle_counts.values())\n",
        "            condition = \"heavy\" if total > 30 else \"moderate\" if total > 15 else \"light\"\n",
        "            return f\"The video shows {total} vehicles ({', '.join([f'{v}: {c}' for v, c in vehicle_counts.items()])}), with {condition} traffic, peaking at {max_vehicles} vehicles at {max_time_sec:.2f}s.\"\n",
        "        if any(kw in question for kw in [\"would\", \"might\", \"could\", \"cause\"]):\n",
        "            return f\"Based on the data, a peak of {max_vehicles} vehicles at {max_time_sec:.2f}s could be due to a traffic signal, intersection delay, or temporary obstruction.\"\n",
        "        return f\"No chatbot available. Summary: {', '.join([f'{v}: {c}' for v, c in vehicle_counts.items()])}.\"\n",
        "\n",
        "    # Chatbot for open-ended and hypothetical questions\n",
        "    try:\n",
        "        is_exploratory = any(kw in question for kw in [\"describe\", \"tell me\", \"what can you say\", \"interesting\", \"summarize\", \"activity\", \"happening\"])\n",
        "        is_hypothetical = any(kw in question for kw in [\"would\", \"might\", \"could\", \"cause\"])\n",
        "\n",
        "        if is_exploratory:\n",
        "            prompt = (\n",
        "                f\"{context}\\n\"\n",
        "                f\"Instruction: Summarize the traffic activity concisely, mentioning vehicle types, counts, speeds, and trends. Start with 'The video shows...'.\\n\"\n",
        "                f\"Question: {question}\\nAnswer:\"\n",
        "            )\n",
        "        elif is_hypothetical:\n",
        "            prompt = (\n",
        "                f\"{context}\\n\"\n",
        "                f\"Instruction: Speculate on the traffic data, discussing possible causes or impacts. Start with 'Based on the data...'.\\n\"\n",
        "                f\"Question: {question}\\nAnswer:\"\n",
        "            )\n",
        "        else:\n",
        "            prompt = (\n",
        "                f\"{context}\\n\"\n",
        "                f\"Instruction: Answer briefly using the data, focusing on counts, speeds, or congestion.\\n\"\n",
        "                f\"Question: {question}\\nAnswer:\"\n",
        "            )\n",
        "\n",
        "        response = chatbot(prompt, max_length=100, num_return_sequences=1)[0]['generated_text'].strip()\n",
        "        if response and len(response) > 5:\n",
        "            sentences = re.split(r'(?<=[.!?])\\s+', response)\n",
        "            return \" \".join(sentences[:min(2, len(sentences))]).strip()\n",
        "        else:\n",
        "            return \"I couldn't generate a response. Please try rephrasing your question.\"\n",
        "    except Exception as e:\n",
        "        print(f\"Chatbot error: {e}\")\n",
        "        return f\"Error processing question. Summary: {', '.join([f'{v}: {c}' for v, c in vehicle_counts.items()])}.\"\n",
        "\n",
        "# Dynamic chat suggestions\n",
        "suggestions = [\n",
        "    \"How many cars were detected in total?\",\n",
        "    \"How many ambulances were in the video?\",\n",
        "    \"How many vehicles at 5 seconds?\",\n",
        "    \"What was the peak traffic time?\",\n",
        "    \"What types of vehicles were detected?\",\n",
        "    \"Tell me about the vehicles in the video.\",\n",
        "    \"What can you say about the traffic flow?\",\n",
        "    \"What was happening in the middle of the video?\",\n",
        "    \"Was there anything interesting in the video?\",\n",
        "    \"What might cause a peak like this?\",\n",
        "    \"How could this data help traffic management?\",\n",
        "    \"What was the average speed of cars?\",\n",
        "    \"How congested was the traffic?\"\n",
        "]\n",
        "if emergency_alerts:\n",
        "    suggestions.append(\"When were ambulances most active?\")\n",
        "\n",
        "# Chat loop with guidance\n",
        "print(\"\\nStarting chat interaction...\")\n",
        "print(\"Video processing complete. Ask any question about the video (type 'exit' to quit).\")\n",
        "print(\"Suggested questions:\")\n",
        "for i, suggestion in enumerate(suggestions, 1):\n",
        "    print(f\"{i}. {suggestion}\")\n",
        "while True:\n",
        "    try:\n",
        "        user_query = input(\"Ask a question: \")\n",
        "        if user_query.lower().strip() == \"exit\":\n",
        "            print(\"Goodbye.\")\n",
        "            break\n",
        "        response = answer_question(user_query, vehicle_counts, frame_vehicle_counts, fps, total_frames, average_counts, max_time_sec, max_vehicles, context, chatbot, average_speeds, congestion_indices, emergency_alerts)\n",
        "        print(\"\\nAnswer:\")\n",
        "        print(response)\n",
        "        print()\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nChat interrupted. Type 'exit' to quit or continue asking questions.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error in chat loop: {e}\")\n",
        "        print(\"Please try again or type 'exit' to quit.\")"
      ],
      "metadata": {
        "id": "kCmBvaKHaOjq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ce272bd753214c4581a663d1352de470",
            "fec4f3a6eec24ee28c5f14b4b1a4af51",
            "db18797e4b6648c888328a7a090d5ead",
            "ffb5dc2afc5d4ea797503b55c1f60d72",
            "ae9f0e3238f4441dac8fb7409fe7e9ca",
            "098716c4cb9c417fbb4300f953b0611d",
            "ee4e7b3f53a947c8a83e0c1f5120b88a",
            "3c72237289e749eba4a7efe8094ee87e",
            "b3bdbf78c05b429baa9865049d3fa24d",
            "82789f95bfe3423cbb3a25a1ef205669",
            "a822574493f84e0aabc213ec46afd117",
            "86dd7f0cba3b48699084fdf2a96247c9",
            "e05cc23f121641fdad20db5e6de206b2",
            "41714b086cdb4f8bb952d88cb7e2dd40",
            "b1d524c540874729af68aa497e7357d4",
            "cf2c8651dd694a59a1807eac671c3206",
            "1c63101885884b3791c41bb36e7802fe",
            "996bda6fdef94f57b80913e213f1b73a",
            "4ccdfe10c1ca40cc91227821740aee15",
            "50d3bf0bf12c4237bf55e327c330dadd",
            "ecd796a699654bdfb1de9a3370410f2f",
            "b1d6d2b3220b48d1ae08f1de92cb4694",
            "21499c6654e84747836989f8a5cb3341",
            "75c39fe1fc95439db2c05780d17a670d",
            "b8303f3f282346c59ac54fedc1f0a869",
            "cf0af215c75042ffac849cffc787f94f",
            "e6f057248c714a9b8b3f666bc86d38ec",
            "1c57704e3fe64a339407c15eddc5d679",
            "0457d42601f1487db124a6749420afdc",
            "834bf2ced6ab42e39b2d6a762d60da14",
            "cd1f0d79716e4838920062323f13a55a",
            "699878b8d2df4b03b7b2395c61b58027",
            "b732d26a7e554eb9b18c319b34b8607b",
            "e94162eac57544aa9f8c10c79771b05f",
            "96a9d9eb6e754379b87811834e760d5d",
            "2384453afe254b518e30ec3c2fc94952",
            "569ab38150214f4aad9ef019d4f98b52",
            "1ea083a00bb34126848df779768c8972",
            "8de0d17a9e2e416f86b2552860fadf81",
            "20230f87c44f43dea784a6a51d3ed7c4",
            "655d1fcfdda1461a80252468a57bfc50",
            "6e274f5418954492a98154057e059592",
            "2039bc802db749a49e50d3d6b084a2bf",
            "f65d6fb15bc34937b64ca3ef20388571",
            "8286ff3f92a942068ffc6be599ae5064",
            "23e71c6333624c44b31a9141585ef837",
            "6ef7e66074ff4b959d8168c4595d36ca",
            "ee7ad369e2a549b8aceb2520a33222b6",
            "82cff09161984fb8b30189706a1f2b98",
            "a00e4c2a89aa4419a11e1178c19eb45b",
            "8b38eed874dc497f8c337d1d2cb7b799",
            "f64c23c26a8f4e48b07c79b79667b7fc",
            "a6107a2ee9b84ed78ba733f506d6f39b",
            "74b6aedf17fd4759a6b4487a5bf0b40f",
            "4fa6657de7894c898eb322f0f19b950b",
            "b315f15b7a894d83bb8e31f52931276b",
            "395239a18aad4603baf4faac7b521161",
            "3b27c3ed61a44a31982dcd720ff42453",
            "367649468c3c40bcb88eb821a229ee93",
            "80ae2fe68489447bbb365affc976a15e",
            "bc96ba90e41d4dd18863eeefd840502b",
            "66ab0df0c6db4ea18eeaaefbf6229987",
            "544c49ae0d8c4835a8cae7a75e8ed6e3",
            "3bcc2edcbd0944e1a0b0853bad38524d",
            "41ce865046724eb286594c902afe5861",
            "9cc9846554d046a78b80dfd8edffa91d",
            "07ed84259ec64b2bb95b76a8010bc6bd",
            "e2099dae21b44c09a78b947f618666ef",
            "5789d402bea1468f94fbd1069fe6d4cc",
            "e3a41a8786e24aad8890e96e1a8bfe6f",
            "07c81bd2c5534e4a9b8487170993c95d",
            "4734d02ab98f4e33a86d4962e3bf167a",
            "f211367c35ad4a998bbc2199a9bc7c11",
            "bddde1a956f7446692d70dae4344d79e",
            "fb41bc8dc71d4a4890249d7933d34098",
            "fcd8d3a102f844d49ccbe4a8071adf51",
            "11ddbc6a2fe945718a84ef589eff3a40"
          ]
        },
        "outputId": "3cd9c60e-6e33-4d8e-9286-e3beb09d54ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing dependencies...\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.111)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cpu)\n",
            "Requirement already satisfied: reportlab in /usr/local/lib/python3.11/dist-packages (4.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.14.1)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cpu)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.11/dist-packages (from reportlab) (5.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "YOLO model loaded successfully.\n",
            "Processing video...\n",
            "\n",
            "0: 480x640 1 Bus, 8 Cars, 99.2ms\n",
            "Speed: 3.3ms preprocess, 99.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 8 Cars, 94.7ms\n",
            "Speed: 2.4ms preprocess, 94.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 8 Cars, 85.5ms\n",
            "Speed: 2.3ms preprocess, 85.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 8 Cars, 82.6ms\n",
            "Speed: 2.4ms preprocess, 82.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 8 Cars, 82.5ms\n",
            "Speed: 2.7ms preprocess, 82.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 8 Cars, 86.5ms\n",
            "Speed: 2.3ms preprocess, 86.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 8 Cars, 85.8ms\n",
            "Speed: 2.6ms preprocess, 85.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 8 Cars, 37.8ms\n",
            "Speed: 2.4ms preprocess, 37.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 9 Cars, 36.8ms\n",
            "Speed: 2.4ms preprocess, 36.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 9 Cars, 82.6ms\n",
            "Speed: 2.5ms preprocess, 82.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 9 Cars, 82.7ms\n",
            "Speed: 2.4ms preprocess, 82.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 9 Cars, 85.3ms\n",
            "Speed: 2.3ms preprocess, 85.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 8 Cars, 82.6ms\n",
            "Speed: 2.3ms preprocess, 82.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 8 Cars, 82.3ms\n",
            "Speed: 2.2ms preprocess, 82.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 8 Cars, 36.8ms\n",
            "Speed: 2.4ms preprocess, 36.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 8 Cars, 38.9ms\n",
            "Speed: 2.6ms preprocess, 38.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 8 Cars, 82.4ms\n",
            "Speed: 2.3ms preprocess, 82.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 8 Cars, 79.5ms\n",
            "Speed: 2.2ms preprocess, 79.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 8 Cars, 81.5ms\n",
            "Speed: 2.3ms preprocess, 81.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 8 Cars, 79.8ms\n",
            "Speed: 2.4ms preprocess, 79.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 9 Cars, 82.9ms\n",
            "Speed: 2.5ms preprocess, 82.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 9 Cars, 84.8ms\n",
            "Speed: 2.3ms preprocess, 84.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 9 Cars, 38.2ms\n",
            "Speed: 2.5ms preprocess, 38.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 9 Cars, 84.7ms\n",
            "Speed: 2.3ms preprocess, 84.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 9 Cars, 80.8ms\n",
            "Speed: 2.5ms preprocess, 80.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 9 Cars, 78.0ms\n",
            "Speed: 2.6ms preprocess, 78.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 9 Cars, 80.0ms\n",
            "Speed: 2.3ms preprocess, 80.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 9 Cars, 79.1ms\n",
            "Speed: 2.3ms preprocess, 79.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 9 Cars, 38.7ms\n",
            "Speed: 2.4ms preprocess, 38.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 10 Cars, 83.8ms\n",
            "Speed: 2.3ms preprocess, 83.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 10 Cars, 80.4ms\n",
            "Speed: 2.2ms preprocess, 80.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 10 Cars, 81.7ms\n",
            "Speed: 2.3ms preprocess, 81.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 10 Cars, 79.8ms\n",
            "Speed: 2.4ms preprocess, 79.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 10 Cars, 82.7ms\n",
            "Speed: 2.3ms preprocess, 82.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 10 Cars, 38.7ms\n",
            "Speed: 2.3ms preprocess, 38.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 10 Cars, 81.9ms\n",
            "Speed: 2.6ms preprocess, 81.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 11 Cars, 78.7ms\n",
            "Speed: 2.3ms preprocess, 78.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 11 Cars, 81.6ms\n",
            "Speed: 2.3ms preprocess, 81.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 11 Cars, 80.1ms\n",
            "Speed: 2.2ms preprocess, 80.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 11 Cars, 80.4ms\n",
            "Speed: 2.3ms preprocess, 80.4ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 11 Cars, 39.4ms\n",
            "Speed: 2.3ms preprocess, 39.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 77.4ms\n",
            "Speed: 2.5ms preprocess, 77.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 11 Cars, 78.4ms\n",
            "Speed: 2.3ms preprocess, 78.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 11 Cars, 81.7ms\n",
            "Speed: 2.4ms preprocess, 81.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 11 Cars, 79.9ms\n",
            "Speed: 2.3ms preprocess, 79.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 11 Cars, 79.6ms\n",
            "Speed: 2.5ms preprocess, 79.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 11 Cars, 37.5ms\n",
            "Speed: 2.4ms preprocess, 37.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 11 Cars, 36.8ms\n",
            "Speed: 2.3ms preprocess, 36.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 10 Cars, 77.4ms\n",
            "Speed: 2.5ms preprocess, 77.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 10 Cars, 83.0ms\n",
            "Speed: 2.1ms preprocess, 83.0ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 10 Cars, 82.2ms\n",
            "Speed: 2.3ms preprocess, 82.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 10 Cars, 79.9ms\n",
            "Speed: 2.2ms preprocess, 79.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 10 Cars, 78.5ms\n",
            "Speed: 2.2ms preprocess, 78.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 11 Cars, 37.2ms\n",
            "Speed: 2.4ms preprocess, 37.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 11 Cars, 37.6ms\n",
            "Speed: 2.3ms preprocess, 37.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 11 Cars, 83.0ms\n",
            "Speed: 2.4ms preprocess, 83.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 84.0ms\n",
            "Speed: 2.5ms preprocess, 84.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 81.6ms\n",
            "Speed: 2.3ms preprocess, 81.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 82.5ms\n",
            "Speed: 2.2ms preprocess, 82.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 36.8ms\n",
            "Speed: 2.5ms preprocess, 36.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 39.2ms\n",
            "Speed: 2.4ms preprocess, 39.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 82.4ms\n",
            "Speed: 2.3ms preprocess, 82.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 81.4ms\n",
            "Speed: 2.4ms preprocess, 81.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 78.2ms\n",
            "Speed: 2.3ms preprocess, 78.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 77.9ms\n",
            "Speed: 2.3ms preprocess, 77.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 81.0ms\n",
            "Speed: 2.3ms preprocess, 81.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 76.9ms\n",
            "Speed: 2.3ms preprocess, 76.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 37.6ms\n",
            "Speed: 2.4ms preprocess, 37.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 37.4ms\n",
            "Speed: 2.2ms preprocess, 37.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 80.9ms\n",
            "Speed: 2.4ms preprocess, 80.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 83.1ms\n",
            "Speed: 2.4ms preprocess, 83.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 79.8ms\n",
            "Speed: 2.3ms preprocess, 79.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 82.8ms\n",
            "Speed: 2.3ms preprocess, 82.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 79.4ms\n",
            "Speed: 2.2ms preprocess, 79.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 38.1ms\n",
            "Speed: 2.4ms preprocess, 38.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 14 Cars, 78.2ms\n",
            "Speed: 2.4ms preprocess, 78.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 14 Cars, 80.3ms\n",
            "Speed: 2.3ms preprocess, 80.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 14 Cars, 83.5ms\n",
            "Speed: 2.2ms preprocess, 83.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 14 Cars, 80.0ms\n",
            "Speed: 2.1ms preprocess, 80.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 14 Cars, 84.0ms\n",
            "Speed: 2.2ms preprocess, 84.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 14 Cars, 37.5ms\n",
            "Speed: 2.3ms preprocess, 37.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 14 Cars, 38.8ms\n",
            "Speed: 2.3ms preprocess, 38.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 14 Cars, 81.3ms\n",
            "Speed: 2.2ms preprocess, 81.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 80.3ms\n",
            "Speed: 2.2ms preprocess, 80.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 79.1ms\n",
            "Speed: 2.3ms preprocess, 79.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 80.7ms\n",
            "Speed: 2.2ms preprocess, 80.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 82.3ms\n",
            "Speed: 2.3ms preprocess, 82.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 40.1ms\n",
            "Speed: 2.2ms preprocess, 40.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 83.9ms\n",
            "Speed: 2.3ms preprocess, 83.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 83.2ms\n",
            "Speed: 2.4ms preprocess, 83.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 80.2ms\n",
            "Speed: 2.3ms preprocess, 80.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 83.0ms\n",
            "Speed: 2.2ms preprocess, 83.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 36.1ms\n",
            "Speed: 45.4ms preprocess, 36.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 38.5ms\n",
            "Speed: 2.4ms preprocess, 38.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 36.1ms\n",
            "Speed: 2.3ms preprocess, 36.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 85.7ms\n",
            "Speed: 2.5ms preprocess, 85.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 83.7ms\n",
            "Speed: 2.7ms preprocess, 83.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 80.0ms\n",
            "Speed: 2.3ms preprocess, 80.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 85.1ms\n",
            "Speed: 2.5ms preprocess, 85.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 38.8ms\n",
            "Speed: 2.4ms preprocess, 38.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 78.6ms\n",
            "Speed: 2.4ms preprocess, 78.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 12 Cars, 84.3ms\n",
            "Speed: 2.2ms preprocess, 84.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 82.0ms\n",
            "Speed: 2.4ms preprocess, 82.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 85.5ms\n",
            "Speed: 2.4ms preprocess, 85.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 12 Cars, 83.2ms\n",
            "Speed: 2.6ms preprocess, 83.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 12 Cars, 81.2ms\n",
            "Speed: 2.3ms preprocess, 81.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 12 Cars, 83.7ms\n",
            "Speed: 2.6ms preprocess, 83.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 12 Cars, 84.0ms\n",
            "Speed: 2.5ms preprocess, 84.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 12 Cars, 38.6ms\n",
            "Speed: 2.4ms preprocess, 38.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 12 Cars, 37.6ms\n",
            "Speed: 2.3ms preprocess, 37.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 12 Cars, 81.3ms\n",
            "Speed: 2.4ms preprocess, 81.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 80.0ms\n",
            "Speed: 2.4ms preprocess, 80.0ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 80.5ms\n",
            "Speed: 2.2ms preprocess, 80.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 82.6ms\n",
            "Speed: 2.3ms preprocess, 82.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 83.5ms\n",
            "Speed: 2.2ms preprocess, 83.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 37.4ms\n",
            "Speed: 2.3ms preprocess, 37.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 36.8ms\n",
            "Speed: 2.3ms preprocess, 36.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 82.4ms\n",
            "Speed: 2.5ms preprocess, 82.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 79.8ms\n",
            "Speed: 2.3ms preprocess, 79.8ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 80.7ms\n",
            "Speed: 2.3ms preprocess, 80.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 78.9ms\n",
            "Speed: 2.3ms preprocess, 78.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 77.9ms\n",
            "Speed: 2.2ms preprocess, 77.9ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 79.4ms\n",
            "Speed: 2.2ms preprocess, 79.4ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 78.7ms\n",
            "Speed: 2.2ms preprocess, 78.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 38.1ms\n",
            "Speed: 2.6ms preprocess, 38.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 78.9ms\n",
            "Speed: 2.2ms preprocess, 78.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 81.3ms\n",
            "Speed: 2.5ms preprocess, 81.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 79.0ms\n",
            "Speed: 2.2ms preprocess, 79.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 81.5ms\n",
            "Speed: 2.4ms preprocess, 81.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 80.9ms\n",
            "Speed: 2.6ms preprocess, 80.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 11 Cars, 79.2ms\n",
            "Speed: 2.2ms preprocess, 79.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 11 Cars, 39.2ms\n",
            "Speed: 2.4ms preprocess, 39.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 11 Cars, 85.3ms\n",
            "Speed: 2.2ms preprocess, 85.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 11 Cars, 79.2ms\n",
            "Speed: 2.3ms preprocess, 79.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 11 Cars, 84.1ms\n",
            "Speed: 2.4ms preprocess, 84.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 11 Cars, 80.9ms\n",
            "Speed: 2.3ms preprocess, 80.9ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 11 Cars, 82.5ms\n",
            "Speed: 2.2ms preprocess, 82.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 11 Cars, 36.8ms\n",
            "Speed: 46.5ms preprocess, 36.8ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 11 Cars, 37.5ms\n",
            "Speed: 2.3ms preprocess, 37.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 11 Cars, 37.7ms\n",
            "Speed: 2.2ms preprocess, 37.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 11 Cars, 84.2ms\n",
            "Speed: 2.4ms preprocess, 84.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 11 Cars, 81.7ms\n",
            "Speed: 2.1ms preprocess, 81.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 11 Cars, 83.3ms\n",
            "Speed: 2.2ms preprocess, 83.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 11 Cars, 81.6ms\n",
            "Speed: 2.4ms preprocess, 81.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 11 Cars, 79.2ms\n",
            "Speed: 2.2ms preprocess, 79.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 11 Cars, 81.0ms\n",
            "Speed: 2.3ms preprocess, 81.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 11 Cars, 36.5ms\n",
            "Speed: 2.2ms preprocess, 36.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 11 Cars, 38.6ms\n",
            "Speed: 2.3ms preprocess, 38.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 11 Cars, 83.9ms\n",
            "Speed: 2.5ms preprocess, 83.9ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 11 Cars, 84.2ms\n",
            "Speed: 2.1ms preprocess, 84.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 11 Cars, 84.0ms\n",
            "Speed: 2.2ms preprocess, 84.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 11 Cars, 81.5ms\n",
            "Speed: 2.2ms preprocess, 81.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 11 Cars, 83.6ms\n",
            "Speed: 2.3ms preprocess, 83.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 37.3ms\n",
            "Speed: 2.7ms preprocess, 37.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 81.0ms\n",
            "Speed: 2.4ms preprocess, 81.0ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 82.4ms\n",
            "Speed: 2.3ms preprocess, 82.4ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 81.1ms\n",
            "Speed: 2.4ms preprocess, 81.1ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 81.4ms\n",
            "Speed: 2.4ms preprocess, 81.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 83.1ms\n",
            "Speed: 2.3ms preprocess, 83.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 83.3ms\n",
            "Speed: 2.3ms preprocess, 83.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 37.4ms\n",
            "Speed: 2.3ms preprocess, 37.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 13 Cars, 80.5ms\n",
            "Speed: 2.2ms preprocess, 80.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 83.6ms\n",
            "Speed: 2.3ms preprocess, 83.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 84.1ms\n",
            "Speed: 2.2ms preprocess, 84.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 85.7ms\n",
            "Speed: 2.2ms preprocess, 85.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 79.8ms\n",
            "Speed: 2.0ms preprocess, 79.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 38.6ms\n",
            "Speed: 2.2ms preprocess, 38.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 85.3ms\n",
            "Speed: 2.1ms preprocess, 85.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 83.4ms\n",
            "Speed: 2.2ms preprocess, 83.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 81.9ms\n",
            "Speed: 2.3ms preprocess, 81.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 84.0ms\n",
            "Speed: 2.2ms preprocess, 84.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 14 Cars, 84.1ms\n",
            "Speed: 2.1ms preprocess, 84.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 14 Cars, 82.3ms\n",
            "Speed: 2.3ms preprocess, 82.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 14 Cars, 37.7ms\n",
            "Speed: 2.1ms preprocess, 37.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 14 Cars, 38.5ms\n",
            "Speed: 2.1ms preprocess, 38.5ms inference, 46.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 14 Cars, 84.7ms\n",
            "Speed: 2.3ms preprocess, 84.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 84.3ms\n",
            "Speed: 2.1ms preprocess, 84.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 82.9ms\n",
            "Speed: 2.1ms preprocess, 82.9ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 84.4ms\n",
            "Speed: 2.0ms preprocess, 84.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 78.1ms\n",
            "Speed: 2.2ms preprocess, 78.1ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 39.7ms\n",
            "Speed: 2.3ms preprocess, 39.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 36.0ms\n",
            "Speed: 2.3ms preprocess, 36.0ms inference, 43.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 83.2ms\n",
            "Speed: 2.3ms preprocess, 83.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 83.9ms\n",
            "Speed: 2.2ms preprocess, 83.9ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 81.2ms\n",
            "Speed: 2.4ms preprocess, 81.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 86.2ms\n",
            "Speed: 2.1ms preprocess, 86.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 36.2ms\n",
            "Speed: 46.7ms preprocess, 36.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 38.5ms\n",
            "Speed: 2.2ms preprocess, 38.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 38.0ms\n",
            "Speed: 2.2ms preprocess, 38.0ms inference, 42.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 84.4ms\n",
            "Speed: 2.2ms preprocess, 84.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 78.8ms\n",
            "Speed: 2.1ms preprocess, 78.8ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 83.4ms\n",
            "Speed: 2.1ms preprocess, 83.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 Buss, 11 Cars, 82.7ms\n",
            "Speed: 2.2ms preprocess, 82.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 84.4ms\n",
            "Speed: 2.1ms preprocess, 84.4ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 41.1ms\n",
            "Speed: 2.3ms preprocess, 41.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 12 Cars, 82.8ms\n",
            "Speed: 2.2ms preprocess, 82.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 81.3ms\n",
            "Speed: 2.2ms preprocess, 81.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 85.7ms\n",
            "Speed: 2.3ms preprocess, 85.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 84.0ms\n",
            "Speed: 2.2ms preprocess, 84.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 82.1ms\n",
            "Speed: 2.1ms preprocess, 82.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 39.6ms\n",
            "Speed: 2.2ms preprocess, 39.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 79.8ms\n",
            "Speed: 2.2ms preprocess, 79.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 81.5ms\n",
            "Speed: 2.1ms preprocess, 81.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 82.0ms\n",
            "Speed: 2.3ms preprocess, 82.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 Buss, 11 Cars, 84.4ms\n",
            "Speed: 2.2ms preprocess, 84.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 Buss, 11 Cars, 40.7ms\n",
            "Speed: 2.4ms preprocess, 40.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 12 Cars, 83.4ms\n",
            "Speed: 2.5ms preprocess, 83.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 81.5ms\n",
            "Speed: 2.5ms preprocess, 81.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 81.7ms\n",
            "Speed: 2.3ms preprocess, 81.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 84.5ms\n",
            "Speed: 2.3ms preprocess, 84.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 82.6ms\n",
            "Speed: 2.2ms preprocess, 82.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 11 Cars, 38.5ms\n",
            "Speed: 2.2ms preprocess, 38.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 11 Cars, 88.9ms\n",
            "Speed: 2.2ms preprocess, 88.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 11 Cars, 83.4ms\n",
            "Speed: 2.5ms preprocess, 83.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 11 Cars, 84.4ms\n",
            "Speed: 2.2ms preprocess, 84.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 11 Cars, 81.2ms\n",
            "Speed: 2.4ms preprocess, 81.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 11 Cars, 38.5ms\n",
            "Speed: 2.2ms preprocess, 38.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 11 Cars, 82.6ms\n",
            "Speed: 2.2ms preprocess, 82.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 11 Cars, 83.1ms\n",
            "Speed: 2.1ms preprocess, 83.1ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 11 Cars, 81.7ms\n",
            "Speed: 2.2ms preprocess, 81.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 11 Cars, 81.2ms\n",
            "Speed: 2.4ms preprocess, 81.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 11 Cars, 83.1ms\n",
            "Speed: 2.3ms preprocess, 83.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 11 Cars, 37.8ms\n",
            "Speed: 45.3ms preprocess, 37.8ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 11 Cars, 37.2ms\n",
            "Speed: 2.4ms preprocess, 37.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 11 Cars, 36.0ms\n",
            "Speed: 2.2ms preprocess, 36.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 11 Cars, 87.2ms\n",
            "Speed: 2.2ms preprocess, 87.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 11 Cars, 83.8ms\n",
            "Speed: 2.0ms preprocess, 83.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 11 Cars, 82.5ms\n",
            "Speed: 2.1ms preprocess, 82.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 11 Cars, 80.6ms\n",
            "Speed: 2.3ms preprocess, 80.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 11 Cars, 79.2ms\n",
            "Speed: 2.1ms preprocess, 79.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 11 Cars, 83.7ms\n",
            "Speed: 2.2ms preprocess, 83.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 10 Cars, 37.2ms\n",
            "Speed: 2.2ms preprocess, 37.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 10 Cars, 40.1ms\n",
            "Speed: 2.4ms preprocess, 40.1ms inference, 42.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 10 Cars, 83.0ms\n",
            "Speed: 2.5ms preprocess, 83.0ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 10 Cars, 80.3ms\n",
            "Speed: 2.4ms preprocess, 80.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 10 Cars, 82.2ms\n",
            "Speed: 2.2ms preprocess, 82.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 10 Cars, 81.9ms\n",
            "Speed: 2.4ms preprocess, 81.9ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 10 Cars, 83.4ms\n",
            "Speed: 2.1ms preprocess, 83.4ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 10 Cars, 38.8ms\n",
            "Speed: 2.5ms preprocess, 38.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 10 Cars, 37.8ms\n",
            "Speed: 2.4ms preprocess, 37.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 11 Cars, 85.4ms\n",
            "Speed: 2.3ms preprocess, 85.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 11 Cars, 81.9ms\n",
            "Speed: 2.4ms preprocess, 81.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 11 Cars, 85.5ms\n",
            "Speed: 2.2ms preprocess, 85.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 11 Cars, 81.6ms\n",
            "Speed: 2.2ms preprocess, 81.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 11 Cars, 82.0ms\n",
            "Speed: 2.3ms preprocess, 82.0ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 12 Cars, 37.3ms\n",
            "Speed: 2.4ms preprocess, 37.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 12 Cars, 84.8ms\n",
            "Speed: 2.5ms preprocess, 84.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 12 Cars, 83.5ms\n",
            "Speed: 2.2ms preprocess, 83.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 12 Cars, 85.2ms\n",
            "Speed: 2.3ms preprocess, 85.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 82.2ms\n",
            "Speed: 2.5ms preprocess, 82.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 82.0ms\n",
            "Speed: 2.2ms preprocess, 82.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 40.5ms\n",
            "Speed: 2.3ms preprocess, 40.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 82.0ms\n",
            "Speed: 2.3ms preprocess, 82.0ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 82.3ms\n",
            "Speed: 2.3ms preprocess, 82.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 83.3ms\n",
            "Speed: 2.3ms preprocess, 83.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 83.9ms\n",
            "Speed: 2.3ms preprocess, 83.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 82.2ms\n",
            "Speed: 2.1ms preprocess, 82.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 38.2ms\n",
            "Speed: 39.5ms preprocess, 38.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 12 Cars, 83.6ms\n",
            "Speed: 2.6ms preprocess, 83.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 12 Cars, 84.6ms\n",
            "Speed: 3.1ms preprocess, 84.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 12 Cars, 81.6ms\n",
            "Speed: 2.2ms preprocess, 81.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 12 Cars, 79.9ms\n",
            "Speed: 2.5ms preprocess, 79.9ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 12 Cars, 80.5ms\n",
            "Speed: 3.2ms preprocess, 80.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 12 Cars, 38.1ms\n",
            "Speed: 2.6ms preprocess, 38.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 11 Cars, 82.3ms\n",
            "Speed: 2.7ms preprocess, 82.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 11 Cars, 82.2ms\n",
            "Speed: 2.4ms preprocess, 82.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 11 Cars, 86.2ms\n",
            "Speed: 2.6ms preprocess, 86.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 14 Cars, 82.8ms\n",
            "Speed: 2.5ms preprocess, 82.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 14 Cars, 79.2ms\n",
            "Speed: 2.4ms preprocess, 79.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 14 Cars, 41.1ms\n",
            "Speed: 2.7ms preprocess, 41.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 14 Cars, 82.2ms\n",
            "Speed: 2.4ms preprocess, 82.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 14 Cars, 82.3ms\n",
            "Speed: 2.6ms preprocess, 82.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 14 Cars, 80.0ms\n",
            "Speed: 2.4ms preprocess, 80.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 14 Cars, 80.8ms\n",
            "Speed: 2.6ms preprocess, 80.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 15 Cars, 79.3ms\n",
            "Speed: 2.5ms preprocess, 79.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 15 Cars, 80.6ms\n",
            "Speed: 2.4ms preprocess, 80.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 15 Cars, 38.2ms\n",
            "Speed: 2.6ms preprocess, 38.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 15 Cars, 81.0ms\n",
            "Speed: 2.6ms preprocess, 81.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 15 Cars, 83.0ms\n",
            "Speed: 2.4ms preprocess, 83.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 84.2ms\n",
            "Speed: 2.5ms preprocess, 84.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 13 Cars, 84.1ms\n",
            "Speed: 2.5ms preprocess, 84.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 13 Cars, 39.8ms\n",
            "Speed: 2.6ms preprocess, 39.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 38.1ms\n",
            "Speed: 2.3ms preprocess, 38.1ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 85.3ms\n",
            "Speed: 2.3ms preprocess, 85.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 15 Cars, 82.5ms\n",
            "Speed: 2.6ms preprocess, 82.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 83.7ms\n",
            "Speed: 2.6ms preprocess, 83.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 13 Cars, 83.0ms\n",
            "Speed: 2.5ms preprocess, 83.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 13 Cars, 38.9ms\n",
            "Speed: 2.7ms preprocess, 38.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 13 Cars, 37.9ms\n",
            "Speed: 2.5ms preprocess, 37.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 13 Cars, 82.4ms\n",
            "Speed: 2.4ms preprocess, 82.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Bus, 12 Cars, 85.5ms\n",
            "Speed: 2.4ms preprocess, 85.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 12 Cars, 84.6ms\n",
            "Speed: 2.7ms preprocess, 84.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 12 Cars, 82.9ms\n",
            "Speed: 2.5ms preprocess, 82.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 12 Cars, 37.7ms\n",
            "Speed: 2.4ms preprocess, 37.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 12 Cars, 38.5ms\n",
            "Speed: 2.4ms preprocess, 38.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 12 Cars, 82.1ms\n",
            "Speed: 2.4ms preprocess, 82.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 12 Cars, 84.6ms\n",
            "Speed: 2.5ms preprocess, 84.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 12 Cars, 85.0ms\n",
            "Speed: 2.6ms preprocess, 85.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 12 Cars, 83.7ms\n",
            "Speed: 2.6ms preprocess, 83.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 11 Cars, 81.8ms\n",
            "Speed: 2.5ms preprocess, 81.8ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 Van, 11 Cars, 80.6ms\n",
            "Speed: 2.8ms preprocess, 80.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Video processing complete: 301 frames processed.\n",
            "Calculating average speeds...\n",
            "Middle frame saved as 'middle_frame.jpg'.\n",
            "Peak frame saved as 'peak_frame.jpg'.\n",
            "Loading report pipeline...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flan-T5-Small loaded for report generation.\n",
            "Loading Flan-T5-Large chatbot model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ce272bd753214c4581a663d1352de470"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/3.13G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "86dd7f0cba3b48699084fdf2a96247c9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "21499c6654e84747836989f8a5cb3341"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e94162eac57544aa9f8c10c79771b05f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8286ff3f92a942068ffc6be599ae5064"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b315f15b7a894d83bb8e31f52931276b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "07ed84259ec64b2bb95b76a8010bc6bd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flan-T5-Large loaded for chatbot.\n",
            "Generating traffic density heatmap...\n",
            "Heatmap saved as 'heatmap.png'.\n",
            "Exporting data to CSV...\n",
            "Traffic data exported to 'traffic_data.csv'.\n",
            "Generating text report...\n",
            "Text report generated with text model.\n",
            "\n",
            "--- Generated Report ---\n",
            "\n",
            "Vehicle Detection Report: Vehicles are grouped into two frames: Car and Bus.\n",
            "Generating visualization dashboard...\n",
            "Dashboard saved as 'dashboard.png'.\n",
            "Generating PDF report...\n",
            "PDF report generated as 'report.pdf'.\n",
            "\n",
            "Chatbot context:\n",
            " Video Analysis: 301 frames, 10.03s, 30.00 FPS.\n",
            "Unique vehicles: Car: 18, Bus: 1 (total: 19).\n",
            "Average per frame: Car: 3.11, Bus: 0.02.\n",
            "Average speeds (pixels/s): Car: 37.69, Bus: 15.82.\n",
            "Peak traffic: 5 vehicles at 1.33s.\n",
            "Middle frame (5.00s): Car: 4.\n",
            "Vehicle types: Car, Bus.\n",
            "Traffic: Moderate.\n",
            "Congestion index: 0.63 (0=low, 1=moderate, >2=high).\n",
            "\n",
            "\n",
            "Starting chat interaction...\n",
            "Video processing complete. Ask any question about the video (type 'exit' to quit).\n",
            "Suggested questions:\n",
            "1. How many cars were detected in total?\n",
            "2. How many ambulances were in the video?\n",
            "3. How many vehicles at 5 seconds?\n",
            "4. What was the peak traffic time?\n",
            "5. What types of vehicles were detected?\n",
            "6. Tell me about the vehicles in the video.\n",
            "7. What can you say about the traffic flow?\n",
            "8. What was happening in the middle of the video?\n",
            "9. Was there anything interesting in the video?\n",
            "10. What might cause a peak like this?\n",
            "11. How could this data help traffic management?\n",
            "12. What was the average speed of cars?\n",
            "13. How congested was the traffic?\n"
          ]
        }
      ]
    }
  ]
}